{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11764452,"sourceType":"datasetVersion","datasetId":7385619},{"sourceId":11765411,"sourceType":"datasetVersion","datasetId":7386187},{"sourceId":11765527,"sourceType":"datasetVersion","datasetId":7386262}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## yolov-12","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T23:46:21.054431Z","iopub.execute_input":"2025-05-10T23:46:21.054798Z","iopub.status.idle":"2025-05-10T23:47:41.572860Z","shell.execute_reply.started":"2025-05-10T23:46:21.054773Z","shell.execute_reply":"2025-05-10T23:47:41.572159Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T23:47:53.573203Z","iopub.execute_input":"2025-05-10T23:47:53.573816Z","iopub.status.idle":"2025-05-10T23:47:57.757259Z","shell.execute_reply.started":"2025-05-10T23:47:53.573789Z","shell.execute_reply":"2025-05-10T23:47:57.756337Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes = [\"Glioma\", \"Meningioma\", \"No Tumor\", \"Pituitary\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T23:47:58.388231Z","iopub.execute_input":"2025-05-10T23:47:58.388581Z","iopub.status.idle":"2025-05-10T23:47:58.392449Z","shell.execute_reply.started":"2025-05-10T23:47:58.388563Z","shell.execute_reply":"2025-05-10T23:47:58.391696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load the YOLO model\nmodel = YOLO('yolo12m.pt')  # Ensure this weight file exists\n\n# Train the model\nmodel.train(data='/kaggle/input/brain-tumor-dataset/data.yaml', epochs=30, batch=15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T01:12:57.248163Z","iopub.execute_input":"2025-05-11T01:12:57.248860Z","iopub.status.idle":"2025-05-11T02:51:20.353411Z","shell.execute_reply.started":"2025-05-11T01:12:57.248834Z","shell.execute_reply":"2025-05-11T02:51:20.352393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model = YOLO('/kaggle/working/runs/detect/train4/weights/best.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T02:59:45.920460Z","iopub.execute_input":"2025-05-11T02:59:45.920815Z","iopub.status.idle":"2025-05-11T02:59:46.087149Z","shell.execute_reply.started":"2025-05-11T02:59:45.920783Z","shell.execute_reply":"2025-05-11T02:59:46.085977Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = best_model(['/kaggle/input/brain-tumor-dataset/train/images/Tr-gl_0124_jpg.rf.167286373f035bde76f3cc25fc6eed91.jpg'])  # return a list of Results objects\nresult = results[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:02:14.815242Z","iopub.execute_input":"2025-05-11T03:02:14.815551Z","iopub.status.idle":"2025-05-11T03:02:14.878430Z","shell.execute_reply.started":"2025-05-11T03:02:14.815530Z","shell.execute_reply":"2025-05-11T03:02:14.877945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(result.plot())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:02:18.822008Z","iopub.execute_input":"2025-05-11T03:02:18.822545Z","iopub.status.idle":"2025-05-11T03:02:19.044432Z","shell.execute_reply.started":"2025-05-11T03:02:18.822520Z","shell.execute_reply":"2025-05-11T03:02:19.043770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\n\n# Load local image (no need for requests)\nimage_path = '/kaggle/input/brain-tumor-dataset/train/images/Tr-gl_0124_jpg.rf.167286373f035bde76f3cc25fc6eed91.jpg'\nimg = Image.open(image_path).convert(\"RGB\")\n\n# Predict using YOLO\nresult = best_model.predict(img)[0]\n\n# Display result\nplt.figure(figsize=(8, 8))\nplt.imshow(img)\nax = plt.gca()\n\n# Draw boxes\nfor detection in result.boxes:\n    x1, y1, x2, y2 = detection.xyxy[0].cpu().numpy()\n    conf = detection.conf[0].cpu().numpy()\n    cls = detection.cls[0].cpu().numpy()\n    rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1,\n                         linewidth=2, edgecolor='red', facecolor='none')\n    ax.add_patch(rect)\n    plt.text(x1, y1, f\"{classes[int(cls)]} {conf:.2f}\", color='white',\n             fontsize=12, backgroundcolor='red')\n\nplt.title('YOLOv12 Detection on Sample Image')\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:02:32.141010Z","iopub.execute_input":"2025-05-11T03:02:32.141298Z","iopub.status.idle":"2025-05-11T03:02:32.398022Z","shell.execute_reply.started":"2025-05-11T03:02:32.141275Z","shell.execute_reply":"2025-05-11T03:02:32.397278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nfrom ultralytics import YOLO\nimport os\n\n# === STEP 1: Define paths ===\nvideo_path = \"/kaggle/input/mri-video/3396561117-preview.mp4\"  # üîÅ Replace with your uploaded file\noutput_path = \"/kaggle/working/annotated_output.mp4\"\nmodel_path = \"/kaggle/working/runs/detect/train4/weights/best.pt\"  # üîÅ Replace with your trained model path\n\n# === STEP 2: Load YOLOv8 model ===\nmodel = YOLO(model_path)\n\n# === STEP 3: Open the uploaded video ===\ncap = cv2.VideoCapture(video_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# === STEP 4: Define video writer ===\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# === STEP 5: Predict and write bounding boxes ===\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    results = model.predict(frame, verbose=False)[0]\n\n    for box in results.boxes:\n        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n        conf = box.conf[0].item()\n        cls = int(box.cls[0].item())\n        label = f\"{model.names[cls]} {conf:.2f}\"\n        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n        cv2.putText(frame, label, (x1, y1 - 10),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\nprint(\"‚úÖ Annotated video saved at:\", output_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:15:14.975437Z","iopub.execute_input":"2025-05-11T03:15:14.975785Z","iopub.status.idle":"2025-05-11T03:15:23.106847Z","shell.execute_reply.started":"2025-05-11T03:15:14.975761Z","shell.execute_reply":"2025-05-11T03:15:23.106127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\n\n# === STEP 1: Define paths ===\nvideo_path = \"/kaggle/input/mri-video/3396561117-preview.mp4\"\noutput_path = \"/kaggle/working/annotated_output.mp4\"\nmodel_path = \"/kaggle/working/runs/detect/train4/weights/best.pt\"\n\n# === STEP 2: Your custom class names ===\ncustom_classes = [\"Glioma\", \"Meningioma\", \"No Tumor\", \"Pituitary\"]\n\n# === STEP 3: Load the YOLO model ===\nmodel = YOLO(model_path)\n\n# === STEP 4: Open video ===\ncap = cv2.VideoCapture(video_path)\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\n# === STEP 5: Set up video writer ===\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n\n# === STEP 6: Predict and annotate ===\nframe_count = 0\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    frame_count += 1\n\n    results = model.predict(frame, verbose=False)[0]\n    results.names = {i: name for i, name in enumerate(custom_classes)}  # ‚úÖ Set names in result\n\n    for box in results.boxes:\n        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n        conf = box.conf[0].item()\n        cls = int(box.cls[0].item())\n        label = f\"{results.names[cls]} {conf:.2f}\"\n        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n        cv2.putText(frame, label, (x1, y1 - 10),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n\n    out.write(frame)\n\n    # Show first 3 frames\n    if frame_count <= 3:\n        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n        plt.title(f\"Frame {frame_count}\")\n        plt.axis('off')\n        plt.show()\n\ncap.release()\nout.release()\n\nprint(\"‚úÖ Annotated video saved at:\", output_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T03:20:22.269182Z","iopub.execute_input":"2025-05-11T03:20:22.269903Z","iopub.status.idle":"2025-05-11T03:20:30.920064Z","shell.execute_reply.started":"2025-05-11T03:20:22.269876Z","shell.execute_reply":"2025-05-11T03:20:30.919427Z"}},"outputs":[],"execution_count":null}]}